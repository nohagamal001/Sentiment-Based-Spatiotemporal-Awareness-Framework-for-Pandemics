{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "6kw-IcMg4Ps_",
    "outputId": "cf484ca5-a148-4c4b-d27a-5a436ff1b7f5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "dataset_path = os.path.join(base_dir, \"covid_tweets_with_sentiments_2021-08-26.csv\")\n",
    "df = pd.read_csv(dataset_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "40DAVJh5wTGy",
    "outputId": "65f9f5d8-573e-46ea-c66a-7cd2498cdaeb"
   },
   "outputs": [],
   "source": [
    "df = df[df['sentiment'].notna()]\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-h7fP6o44Xf"
   },
   "outputs": [],
   "source": [
    "# Assigning numerical values and storing in another column\n",
    "labelencoder = LabelEncoder()\n",
    "df['sentiment_label'] = labelencoder.fit_transform(df['sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "mG9xuPo1ilII",
    "outputId": "ac775cc7-28ea-45b2-9cdb-5876f51fe85e"
   },
   "outputs": [],
   "source": [
    "df = df[df['cleaned_text'].notna()]\n",
    "df['input'] = df['user_name'] + \" \" + df['user_location'] + \" \" + df['cleaned_text']\n",
    "df = df[df['input'].notna()]\n",
    "df.sentiment_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "9ECfRi-DD5Ha",
    "outputId": "cb4c210a-8edb-4e29-9a5f-8e01b30523b0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def to_one_hot(labels, dimension=3):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "\n",
    "maxlen = 280\n",
    "max_words = 40000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(df['input'])\n",
    "sequences = tokenizer.texts_to_sequences(df['input'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "one_hot_labels = to_one_hot(df['sentiment_label'])\n",
    "labels = np.asarray(one_hot_labels)\n",
    "\n",
    "\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "\n",
    "# splitting dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZFH_G83H7wvb",
    "outputId": "76d0ff0c-326a-488c-c962-c50ba9885398"
   },
   "outputs": [],
   "source": [
    "print(labels.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-4u-l1FRLFLB",
    "outputId": "d94d4154-4544-4038-e439-00255c9c4f15"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Bidirectional(layers.LSTM(32,return_sequences = True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Bidirectional(layers.LSTM(32, return_sequences= True)))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "valid_split = 0.2\n",
    "batch_size_no = 16\n",
    "epochs_no = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "id": "m8uMuCIRtIYw",
    "outputId": "93134001-a6c8-4361-cde7-90d766350d8c"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = epochs_no, \n",
    "                    batch_size = batch_size_no,\n",
    "                    validation_split = valid_split, \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(base_dir, \"sentiment_analysis_bi_lstm_{}_observations_{}_epochs_{}_batchsize.h5\".format(df.shape[0], epochs_no, batch_size_no))\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "pmBiZVD2Lrv_",
    "outputId": "53830f59-fc29-4cb7-81b0-a252c43d8b35"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_val_pred = model.predict_classes(X_test)\n",
    "\n",
    "rounded_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(rounded_labels, y_val_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(rounded_labels, y_val_pred, average = 'weighted')\n",
    "print('Precision: %f' %precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(rounded_labels, y_val_pred, average = 'weighted')\n",
    "print('Recall: %f' %recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(rounded_labels, y_val_pred, average = 'weighted')\n",
    "print('F1: %f' %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "re7FEDjrLt-f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "sentiment140_bi_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
